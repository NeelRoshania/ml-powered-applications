{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Powered Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4\n",
    "\n",
    "Data exploration notebook to better understand the data.\n",
    "\n",
    "Objective\n",
    "- To label and identify trends\n",
    "\n",
    "Process\n",
    "- Generate summary statistics\n",
    "- Identifying differences in class distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run script on a 3.6 environment - base36\n",
    "!pip install -U spacy\n",
    "!pip install -U umap-learn\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# intialization\n",
    "PATH_data = r\"C:\\Users\\nrosh\\Desktop\\Personal Coding Projects\\Python\\ml-powered-applications\\neel\\data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions\n",
    "\n",
    "1. Clustering\n",
    "    - Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters)\n",
    "    - Many clustering algorithms group data points by measuring the distance between points and assigning ones that are close to each other to the same cluster.\n",
    "    - The vast majority of datasets can be separated into clusters based on their features, labels, or a combination of both. Examining each cluster individually and the similarities and differences between clusters is a great way to identify structure in a dataset.\n",
    "    - Clustering algorithms work on vectors, so we canâ€™t simply pass a set of sentences to a clustering algorithm. To get our data ready to be clustered, we will first need to vectorize it.\n",
    "\n",
    "2. Vectorization\n",
    "    - A process of converting a raw data set into a singular or multi-dimensional vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization techniques\n",
    "\n",
    "Clustering requires distances to be measured on the \"same\" scale.\n",
    "\n",
    "The approach for vectorizing/normalizing data depends on the structure and type of data being analysed.\n",
    "\n",
    "1. Tabular data\n",
    "    - Continuous features should be normalized to a common scale\n",
    "    - Categorical features such as colors can be converted to a one-hot encoding (binary transformations). This allows the distance between points to always remain the same.\n",
    "    \n",
    "2. Text data\n",
    "\n",
    "    - Bag Of Words (Tokenize sentences and count their observations by row)\n",
    "        - The simplest way to vectorize text is to use a count vector, which is the word equivalent of one-hot encoding.\n",
    "        - For each sentence, the number at each index represents the count of occurrences of the associated word in the given sentence.\n",
    "        -This method ignores the order of the words in a sentence\n",
    "        - scikit-learn TfidfVectorizer\n",
    "            - Produce a vector of tokenized words for count aggregation by row\n",
    "            - https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "    - Word2ec and fastText\n",
    "        - These vectorization techniques produce word vectors that attempt to learn a representation that captures similarities between concepts better than a TF-IDF encoding. \n",
    "        - They do this by learning which words tend to appear in similar contexts in large bodies of text such as Wikipedia.\n",
    "        - This approach is based on the distributional hypothesis, which claims that linguistic items with similar distributions have similar meanings.\n",
    "            - This is done by learning a vector for each word and training a model to predict a missing word in a sentence using the word vectors of words around it. \n",
    "            - The number of neighboring words to take into account is called the window size.\n",
    "    - Dimensionality Reduction\n",
    "        - Vectorized data are multi-dimensional and can't be visualized\n",
    "        - The goal is to use a method that reduces multidimensional data into a visual space whilst minimizing the data loss associated with dimensional reduction\n",
    "        - Techniques\n",
    "            - t-SNE\n",
    "            - UMAP\n",
    "        - These techniques are useful for to notice patterns in data on a very high level\n",
    "        - The goal is to use these methods to see whether there are regions of the data that can easily be seperated by a production model\n",
    "        - \n",
    "\n",
    "UMAP\n",
    "    - General purpose manifold learning and dimension reduction algorithm\n",
    "    \n",
    "    \n",
    "Once we have a vectorized representation of our unstructured data, we can use it for the purpose of data inspection/exploration or outcome predictions.\n",
    "\n",
    "1. Inspection\n",
    "        - Dimensionality Reduction\n",
    "             - Vectors produced from unstructured data often have more than one dimension. The dataset needs to be reduced in some way for us to visualize it on a two-dimensional plane.\n",
    "             - \n",
    "\n",
    "2. Prediction\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labelling Strategy\n",
    "Feel free to update your vectorization strategy by adding any features you discover to help make your data representation as informative as possible, and go back to labeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url=\"vectorization_strategy.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics Observed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Are there distinct regions of post's title that can be classified into one or multiple labels?\n",
    "    \n",
    "Sources:\n",
    "- stackexchange: \n",
    "    - Data Schema: https://meta.stackexchange.com/questions/2677/database-schema-documentation-for-the-public-data-dump-and-sede\n",
    "    - Score: https://meta.stackexchange.com/questions/229255/what-is-the-score-of-a-post\n",
    "    - UMAP: https://umap-learn.readthedocs.io/en/latest/\n",
    "    \n",
    "- word2vec: https://code.google.com/archive/p/word2vec/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_df(df, cols, **kwargs):\n",
    "\n",
    "    # rename and return a dataframe of those columns\n",
    "    # choose to export or not\n",
    "    \n",
    "    _df = df.loc[:, cols]\n",
    "    \n",
    "    # rename dict\n",
    "    if \"rename_dict\" in kwargs.keys() :\n",
    "        _df.rename(columns=kwargs[\"rename_dict\"], inplace=True)\n",
    "        print('- Columns renamed.')\n",
    "    \n",
    "    # export data\n",
    "    if kwargs[\"export_loc\"]:\n",
    "        \n",
    "        # handle data export\n",
    "        try:\n",
    "            \n",
    "            if \"export_name\" in kwargs.keys():\n",
    "                _location = kwargs[\"export_loc\"] + \"\\\\{}\".format(kwargs[\"export_name\"]) + \".csv\"\n",
    "                _df.to_csv(_location)\n",
    "                print(f\"\"\"- File exported to: {_location}\"\"\")\n",
    "            else:\n",
    "                _location = kwargs[\"export_loc\"]+\"\\\\adhoc_{}\".format(datetime.today().strftime(\"%m%d%y\"))+\".csv\"\n",
    "                _df.to_csv(_location)\n",
    "                print(f\"\"\"- File exported to: {_location}\"\"\")\n",
    "\n",
    "        except:\n",
    "            raise Exception(f\"\"\"export_loc must be of type str. Given: {type(kwargs[\"export_loc\"])}\"\"\")\n",
    "    \n",
    "    print('\\n')\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingestion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# original\n",
    "df_orig = pd.read_csv(\n",
    "    PATH_data + \"\\\\labelling\\questions_by_cluster.csv\",\n",
    ")\n",
    "\n",
    "# copies\n",
    "df = df_orig.iloc[:, 1::].copy()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling Strategy\n",
    "\n",
    "Goal: \n",
    "1. To produce features that describe each clusters uniquely \n",
    "2. To produce the results you would like it to produce\n",
    "\n",
    "Strategies:\n",
    "\n",
    "1. Update your vectorization strategy by adding any features you discover to help make your data representation as informative as possible, and go back to labeling.\n",
    "2. To speed up your labeling, leverage your prior analysis by labeling a few data points in each cluster and for each common value in your feature distribution.\n",
    "3. Use cluster visualizations to infer characteristics about each data point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Bokeh setup and sources\n",
    "\n",
    "import bokeh.models as bmo\n",
    "import bokeh.plotting as bpl\n",
    "\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.palettes import d3, all_palettes\n",
    "from bokeh.layouts import row, layout\n",
    "from bokeh.models import CheckboxGroup, CustomJS, Panel, CDSView\n",
    "from bokeh.models.tools import HoverTool\n",
    "from bokeh.models.widgets import Tabs\n",
    "# from bokeh.io import show, output_notebook\n",
    "\n",
    "# Last mile conversions\n",
    "df_bokeh                      = df.copy()\n",
    "df_bokeh[\"question_answered\"] = df_bokeh.question_answered.apply(lambda row: \"answered\" if row==True else \"unanswered\")\n",
    "df_bokeh[\"cluster\"]           = df_bokeh.cluster.apply(lambda row: str(row))\n",
    "\n",
    "# define UI Tools\n",
    "TOOLS=\"hover,crosshair,pan,wheel_zoom,zoom_in,zoom_out,box_zoom,undo,redo,reset,tap,save,box_select,poly_select,lasso_select,\"\n",
    "LABELS = [\"Cluster {}\".format(cluster) for cluster in np.sort(df_bokeh.cluster.unique())]\n",
    "\n",
    "# sources\n",
    "df_ans   = df_bokeh.loc[df_bokeh.question_answered == 'answered', :]\n",
    "df_nans  = df_bokeh.loc[df_bokeh.question_answered == 'unanswered', :]\n",
    "\n",
    "src_ans  = bpl.ColumnDataSource(\n",
    "    df_ans.to_dict('list')\n",
    ")\n",
    "\n",
    "src_nans = bpl.ColumnDataSource(\n",
    "    df_nans.to_dict('list')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bokeh function\n",
    "\n",
    "def update(attr, old, new):\n",
    "    \n",
    "    # callback to update source\n",
    "    try:\n",
    "        # Get the list of carriers for the graph\n",
    "        clusters_selected = [i for i in carrier_selection.active]\n",
    "        print(clusters_selected)\n",
    "        \n",
    "        # Update source\n",
    "        new_src_ans = ColumnDataSource(df_ans.loc[df_ans.cluster.isin(clusters_selected), :])\n",
    "        new_src_nans = ColumnDataSource(df_nans.loc[df_nans.cluster.isin(clusters_selected), :])\n",
    "        \n",
    "        # Update the source used in the quad glpyhs\n",
    "        src_ans.data.update(new_src_ans.data)\n",
    "        src_nans.data.update(new_src_nans.data)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "        \n",
    "## calback functions\n",
    "filter_cluster = CustomJS(\n",
    "    args=dict(source=src_ans), \n",
    "    code=\"\"\"\n",
    "        \n",
    "        // initialize\n",
    "        var primary_id = [];\n",
    "        var x = [];\n",
    "        var y = [];\n",
    "        var post_title = [];\n",
    "        var cluster = [];\n",
    "        \n",
    "        // define active checkboxes\n",
    "        let selected_categories = this.active\n",
    "        \n",
    "        // iterate through rows of data source and see if each satisfies some constraint\n",
    "        for (var i = 0; i < source.get_length(); i++){\n",
    "            if (selected_categories.includes(parseInt(source.data['cluster'][i]))){\n",
    "                primary_id.push(source.data['PrimaryId'][i])\n",
    "                x.push(source.data['x'][i])\n",
    "                y.push(source.data['y'][i])\n",
    "                post_title.push(source.data['post_title'][i])\n",
    "                cluster.push(source.data['cluster'][i])\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        console.log(this.active)\n",
    "        console.log(x.length)\n",
    "        source['PrimaryId'] = primary_id\n",
    "        source['x'] = x\n",
    "        source['y'] = y\n",
    "        source['post_title'] = post_title\n",
    "        source['cluster'] = cluster\n",
    "        \n",
    "        source.change.emit();\n",
    "        \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Bokeh worflow\n",
    "\n",
    "# output_notebook()\n",
    "\n",
    "#\n",
    "# Figures and colormaps\n",
    "#\n",
    "\n",
    "p_answered = figure(tools=TOOLS)\n",
    "p_nanswered = figure(tools=TOOLS)\n",
    "\n",
    "ans_cmap = bmo.CategoricalColorMapper(\n",
    "    factors=df_ans.cluster.unique(),\n",
    "    palette=all_palettes['Set1'][len(df_ans.cluster.unique())]\n",
    ")\n",
    "\n",
    "nans_cmap = bmo.CategoricalColorMapper(\n",
    "    factors=df_nans.cluster.unique(),\n",
    "    palette=all_palettes['Set1'][len(df_nans.cluster.unique())]\n",
    ") # this changes the order with which the colors are applied\n",
    "\n",
    "#\n",
    "# Visualizations\n",
    "#\n",
    "\n",
    "p_answered.scatter(\n",
    "    x='x', \n",
    "    y='y',\n",
    "    source=src_ans,\n",
    "    color={'field': 'cluster', 'transform': ans_cmap},\n",
    "    fill_alpha=0.9,\n",
    "    line_color=None,\n",
    "    legend_group='cluster'\n",
    ")\n",
    "\n",
    "# using the color mapped define by answered questions - potential bug\n",
    "p_nanswered.scatter(\n",
    "    x='x', \n",
    "    y='y',\n",
    "    source=src_nans,\n",
    "    color={'field': 'cluster', 'transform': ans_cmap},\n",
    "    fill_alpha=0.9,\n",
    "    line_color=None,\n",
    "    legend_group='cluster'\n",
    ")\n",
    "\n",
    "# Decorations\n",
    "p_answered.title.text = 'Answered questions'\n",
    "p_answered.legend.title = 'Cluster'\n",
    "p_answered.xaxis.axis_label = 'Dimensional x'\n",
    "p_answered.yaxis.axis_label = 'Dimensional y'\n",
    "\n",
    "\n",
    "p_nanswered.title.text = 'Unanswered questions'\n",
    "p_nanswered.legend.title = 'Cluster'\n",
    "p_nanswered.xaxis.axis_label = 'Dimensional x'\n",
    "p_nanswered.yaxis.axis_label = 'Dimensional y'\n",
    "\n",
    "fig_dim = 550\n",
    "p_answered.width = p_nanswered.width = fig_dim\n",
    "p_answered.height = p_nanswered.height = fig_dim\n",
    "\n",
    "# hover parameters\n",
    "hover_answered = HoverTool()\n",
    "hover_answered.tooltips=[\n",
    "    ('Question ', '@question_answered'),\n",
    "    ('Post Question Title', '@post_title'),\n",
    "    ('Cluster', '@cluster'),\n",
    "]\n",
    "\n",
    "hover_nanswered = HoverTool()\n",
    "hover_nanswered.tooltips=[\n",
    "    ('Question ', '@question_answered'),\n",
    "    ('Post Question Title', '@post_title'),\n",
    "    ('Cluster', '@cluster')\n",
    "]\n",
    "\n",
    "p_answered.add_tools(hover_answered)\n",
    "p_nanswered.add_tools(hover_answered)\n",
    "\n",
    "#\n",
    "# Widgets\n",
    "#\n",
    "\n",
    "checkbox_group = CheckboxGroup(labels=LABELS, active=[i for i in range(len(LABELS))])\n",
    "checkbox_group.js_on_change('active', filter_cluster)\n",
    "\n",
    "# checkbox_group.on_change('active', update)\n",
    "\n",
    "# output_file(\"color_scatter.html\", title=\"color_scatter.py example\")\n",
    "\n",
    "# layout specificationns \n",
    "lay = layout(\n",
    "        children = [\n",
    "            [p_answered, p_nanswered],\n",
    "            [checkbox_group],\n",
    "        ]\n",
    ")\n",
    "\n",
    "tab = Panel(child=lay, title = 'Clusters')\n",
    "tabs = Tabs(tabs=[tab])\n",
    "\n",
    "show(tabs)  # open a browser or notebook depending on configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
